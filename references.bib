% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{lewis2020rag,
  title={Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020},
  url={https://arxiv.org/abs/2005.11401}
}

@inproceedings{rajpurkar2018squad,
  title={Know What You Don't Know: Unanswerable Questions for {SQuAD}},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={784--789},
  year={2018},
  address={Melbourne, Australia},
  publisher={Association for Computational Linguistics},
  url={https://arxiv.org/abs/1806.03822}
}

@inproceedings{roberts2020fine,
  title={How Much Knowledge Can You Pack into the Parameters of a Language Model?},
  author={Roberts, Adam and Raffel, Colin and Shazeer, Noam},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={5418--5426},
  year={2020},
  address={Online},
  publisher={Association for Computational Linguistics},
  url={https://arxiv.org/abs/2002.08910}
}

@article{kalai2025hallucinate,
  title={Why Language Models Hallucinate},
  author={Kalai, Adam Tauman and Nachum, Ofir and Vempala, Santosh S. and Zhang, Edwin},
  journal={arXiv preprint arXiv:2509.04664},
  year={2025},
  url={https://arxiv.org/abs/2509.04664}
}

@article{dahl2024legal,
  title={Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models},
  author={Dahl, Matthew and Magesh, Varun and Suzgun, Mirac and Ho, Daniel E.},
  journal={Journal of Legal Analysis},
  volume={16},
  number={1},
  pages={64--93},
  year={2024},
  publisher={Oxford University Press},
  doi={10.1093/jla/laae003},
  url={https://academic.oup.com/jla/article/16/1/64/7699227}
}

@inproceedings{pal2023medhalt,
  title={{M}ed-{HALT}: Medical Domain Hallucination Test for Large Language Models},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)},
  pages={314--334},
  year={2023},
  month={dec},
  address={Singapore},
  publisher={Association for Computational Linguistics},
  doi={10.18653/v1/2023.conll-1.21},
  url={https://aclanthology.org/2023.conll-1.21/}
}

@inproceedings{wei2022cot,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc V. and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022},
  editor={Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  publisher={Curran Associates, Inc.},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}
}

@article{ouyang2022human,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F. and Leike, Jan and Lowe, Ryan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022},
  url={https://arxiv.org/abs/2203.02155}
}